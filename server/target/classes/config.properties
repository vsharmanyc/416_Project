serverStaticWd = server/src/main/resources/static
seaWulfDistrictingThreshold = 5
transferDataBash = /transferDataToSeaWulf.sh
swDataPrefix = /swData_job
precinctDataSuffix = _Precinct_data.json
bashScript = #!/usr/bin/expect\n\nspawn scp swData_job%d.txt panthersm.slurm ../../../../../algorithm/algorithm.py ../../../../../algorithm/Cluster.py ../../../../../algorithm/Graph.py ../../../../../algorithm/Node.py ../../../../../algorithm/Subgraph.py ../../../../../algorithm/Precinct.py ../../../../../algorithm/Request.py jlungu@login.seawulf.stonybrook.edu:/gpfs/scratch/jlungu/%s\nexpect "jlungu@login.seawulf.stonybrook.edu's password:"\nsend "Ifyougiveapigapancake12112!"\ninteract\n
slurmScript = #!/usr/bin/env bash\n#SBATCH --job-name=%s_%d\n#SBATCH --output=%s_%d.log\n#SBATCH --ntasks-per-node=40\n#SBATCH --nodes=%d\n#SBATCH --time=%s\n#SBATCH -p %s\n#SBATCH --mail-type=BEGIN,END\n#SBATCH --mail-user=james.lungu@stonybrook.edu\nmodule load gnu-parallel/6.0\nmodule load mpi4py/3.0.3\nrm -rf result.json\nrm -rf coordinator.log\nrm -rf output1.txt\nrm -rf output2.txt\nrm -rf output0.txt\nrm -rf result0.json\nrm -rf result1.json\nrm -rf result2.json\ntouch output0.txt output1.txt output2.txt result0.json result1.json result2.json\ntouch coordinator.log\necho '{"results": ['>> result.json\necho I am using the following nodes: $SLURM_JOB_NODELIST\necho My job ID is: $SLURM_JOB_ID\ncat << EOF > panthers.py\nimport os\nimport time\nfrom mpi4py import MPI\nstart_time = time.time()\ncomm = MPI.COMM_WORLD\nsize = comm.Get_size()\nrank = comm.Get_rank()\nprint("This is node {}".format(rank))\njob_count = %d\njob_count0_sz3 = ceil(job_count / 3)\njob_count1_sz3 = job_count0_sz3\njob_count2_sz3 = job_count - job_count0_sz3 - job_count1_sz3\njob_count0_sz2 = ceil(job_count/2)\njob_count1_sc2 = job_count - job_count0_sz2\nif rank == 0:\n\t\tprint("We have {} nodes in our cluster.".format(size))\n\t\tdata = [x for x in range(size)]\n\t\tprint('We will be scattering files across nodes:', data)\nelse:\n\t\tdata = None\nif size == 1:\n\t\tjobs = job_count\nelif size == 2:\n\t\tif rank == 0:\n\t\tjobs = job_count0_sz2\nelse:\n\t\tjob_count1_sc2\nelif size == 3:\t\t\nif rank == 0:\njobs = job_count0_sz3\nelif rank == 1:\n\t\tjobs = job_count1_sz3\nelse:\n\t\tjobs = job_count2_sz3\ndata = comm.scatter(data, root=0)\nprint('rank', rank, 'has data:', data)\nprint("Node {} will be completing {} jobs".format(rank, jobs))\nwhile jobs > 0:\n\t\tif jobs > 40:\n\t\ts = ""\n\t\tfname = "info" + str(rank) + ".txt"\n\t\tf = open(fname, "w")\n\t\tfor i in range(1, 41):\n\t\ts += str(rank) + "\\n"\n\t\ts += str(rank)\n\t\tf.write(s)\n\t\tf.close()\n\t\tcommand = "cat " + fname + " | parallel -l1 --jobs 40 python3 algorithm.py".format(data)\n\t\tprint("Running command:", command)\n\t\tos.system(command)\n\t\telse:\n\t\ts = ""\n\t\tfname = "info" + str(rank) + ".txt"\n\t\tf = open(fname, "w")\n\t\tfor i in range(1, jobs+1):\n\t\ts += str(rank) + "\\n"\n\t\ts += str(rank)\nf.write(s)\n\t\tf.close()\n\t\tcommand = "cat " + fname + " | parallel -l1 --jobs " + str(jobs) + " python3 algorithm.py".format(data)\n\t\tprint("Running command:", command)\n\t\tos.system(command)\n\t\tjobs -= 40\ncomm.barrier()\nprint("Completed in {:.2f}s for rank {}:".format(time.time() - start_time, rank))\nEOF\nmpirun -np %s python3 panthers.py\necho ']}'>> result.json
slurmScriptPath = /panthersm.slurm
bashStartJobScriptPath = /startSeaWulfJob.sh